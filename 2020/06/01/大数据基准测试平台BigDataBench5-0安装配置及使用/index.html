<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/32x32%E5%8F%AF%E7%88%B1.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/16x16%E5%A5%B6%E8%8C%B6.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="大数据," />




  


  <link rel="alternate" href="/atom.xml" title="Athenahe的小天地" type="application/atom+xml" />






<meta name="description" content="bigDataBench5.0（2019.6月发布）前提：安装hadoop、jdk、g++、gcc、gsl 1. 首先就是下载BigDataBench安装包http:&#x2F;&#x2F;125.39.136.212:8090&#x2F;BigDataBench&#x2F;BigDataBench_V5.0_BigData_MicroBenchmarkhttp:&#x2F;&#x2F;125.39.136.212:8090&#x2F;BigDataBench&#x2F;Bi">
<meta property="og:type" content="article">
<meta property="og:title" content="大数据基准测试平台BigDataBench5.0安装配置及使用">
<meta property="og:url" content="http://yoursite.com/2020/06/01/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B9%B3%E5%8F%B0BigDataBench5-0%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E5%8F%8A%E4%BD%BF%E7%94%A8/index.html">
<meta property="og:site_name" content="Athenahe的小天地">
<meta property="og:description" content="bigDataBench5.0（2019.6月发布）前提：安装hadoop、jdk、g++、gcc、gsl 1. 首先就是下载BigDataBench安装包http:&#x2F;&#x2F;125.39.136.212:8090&#x2F;BigDataBench&#x2F;BigDataBench_V5.0_BigData_MicroBenchmarkhttp:&#x2F;&#x2F;125.39.136.212:8090&#x2F;BigDataBench&#x2F;Bi">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191110194903181.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191110195154969.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191110195209885.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191111175707847.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191111180002689.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191111180053328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_8,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191111180634265.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191111180823706.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191111181609379.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_8,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191111181744927.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/2019111118184034.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191111181850363.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191111181945752.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191111182029487.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191111185658916.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191111185813179.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20191111185849328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/2019111119391582.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70">
<meta property="article:published_time" content="2020-06-01T02:20:45.000Z">
<meta property="article:modified_time" content="2020-06-01T02:41:19.659Z">
<meta property="article:author" content="Athenahe">
<meta property="article:tag" content="大数据">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20191110194903181.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_16,color_FFFFFF,t_70">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2020/06/01/大数据基准测试平台BigDataBench5-0安装配置及使用/"/>





  <title>大数据基准测试平台BigDataBench5.0安装配置及使用 | Athenahe的小天地</title>
  








<meta name="generator" content="Hexo 4.2.1"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Athenahe的小天地</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">要每天进步一点点呀</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/06/01/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B9%B3%E5%8F%B0BigDataBench5-0%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E5%8F%8A%E4%BD%BF%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Athenahe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Athenahe的小天地">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">大数据基准测试平台BigDataBench5.0安装配置及使用</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-06-01T10:20:45+08:00">
                2020-06-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>bigDataBench5.0（2019.6月发布）<br><strong>前提：安装hadoop、jdk、g++、gcc、gsl</strong></p>
<h2 id="1-首先就是下载BigDataBench安装包"><a href="#1-首先就是下载BigDataBench安装包" class="headerlink" title="1. 首先就是下载BigDataBench安装包"></a>1. 首先就是下载BigDataBench安装包</h2><p><a href="http://125.39.136.212:8090/BigDataBench/BigDataBench_V5.0_BigData_MicroBenchmark" target="_blank" rel="noopener">http://125.39.136.212:8090/BigDataBench/BigDataBench_V5.0_BigData_MicroBenchmark</a><br><a href="http://125.39.136.212:8090/BigDataBench/BigDataBench_V5.0_BigData_ComponentBenchmark" target="_blank" rel="noopener">http://125.39.136.212:8090/BigDataBench/BigDataBench_V5.0_BigData_ComponentBenchmark</a><br>（需要有GitLab账户才可以下载）<br>如果不想注册，可以从这<a href="https://pan.baidu.com/s/1CW8T_bArnbmRzv7J09pu5Q" target="_blank" rel="noopener">下载</a>（提取码：jusb ）。根据自己的系统环境和需要选择合适的安装包（我是ubuntu18.04，所以下载的是tar.gz的包）<br><img src="https://img-blog.csdnimg.cn/20191110194903181.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="2-解压安装包"><a href="#2-解压安装包" class="headerlink" title="2. 解压安装包"></a>2. 解压安装包</h2><p>我解压到了/opt/module下</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$</span> tar <span class="literal">-zxvf</span> BigDataBench_V5.<span class="number">0</span>_BigData_MicroBenchmark.tar.gz <span class="literal">-C</span> /opt/module/</span><br><span class="line"><span class="variable">$</span> tar <span class="literal">-zxvf</span> BigDataBench_V5.<span class="number">0</span>_BigData_ComponentBenchmark.tar.gz <span class="literal">-C</span> /opt/module/</span><br></pre></td></tr></table></figure>
<p>重命名BigDataBench_V5.0_BigData_MicroBenchmark， BigDataBench_V5.0_BigData_ComponentBenchmark（太长了这名字）</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mv BigDataBench_V5.<span class="number">0</span>_BigData_MicroBenchmark BigDataBench5.<span class="number">0</span>_MicroBenchmark</span><br><span class="line">mv BigDataBench_V5.<span class="number">0</span>_BigData_ComponentBenchmark BigDataBench5.<span class="number">0</span>_ComponentBenchmark</span><br></pre></td></tr></table></figure>
<p>解压之后，查看BigDataBench目录结构<br><img src="https://img-blog.csdnimg.cn/20191110195154969.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20191110195209885.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<blockquote>
<p>提示：最好不要直接运行./prepare.sh,会出现编译失败的错误（小伙伴可以尝试一下，没有出错就不用看下面的步骤啦）<br>    原因：它里面的很多文件都太旧了，所以需要手动更新，重新进行make</p>
</blockquote>
<h2 id="3-进入安装目录，进行数据生成器Text-data-generate-的编译"><a href="#3-进入安装目录，进行数据生成器Text-data-generate-的编译" class="headerlink" title="3. 进入安装目录，进行数据生成器Text data generate 的编译"></a>3. 进入安装目录，进行数据生成器Text data generate 的编译</h2><p>Ubuntu下载GSL库并安装(GSL是一个开源的科学计算库,C语言的版本)<br>安装教程参考：<a href="https://blog.csdn.net/weixin_34566605/article/details/103001334" target="_blank" rel="noopener">https://blog.csdn.net/weixin_34566605/article/details/103001334</a></p>
<blockquote>
<p><del>进入BigDataGenratorSuite/Text_datagen里,会看到一个压缩文件gsl-1.15.tar.gz(就是这里面的文件有些旧了，需要重新编译)</del><br><del>cd ./BigDataGeneratorSuite/Text_datagen     解压gsl-1.15.tar.gz     tar -xf<br>gsl-1.15.tar.gz      cd gsl-1.15/<br>    nano@nano1:/opt/module/BigDataBench5.0/BigDataGeneratorSuite/Text_datagen/gsl-1.15$./autogen.sh（生成最新的cofig.guess,config.sub等文件,自带的是2009年的，已经过时了）<br>    nano@nano1:/opt/module/BigDataBench5.0/BigDataGeneratorSuite/Text_datagen/gsl-1.15$./configure<br>    nano@nano1:/opt/module/BigDataBench5.0/BigDataGeneratorSuite/Text_datagen/gsl-1.15$make<br>    nano@nano1:/opt/module/BigDataBench5.0/BigDataGeneratorSuite/Text_datagen/gsl-1.15$sudo<br>make install（必须要有root权限）</del></p>
</blockquote>
<p>编译：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nano@nano10:/opt/module/BigDataBench5.<span class="number">0</span>_MicroBenchmark/BigDataGeneratorSuite/Text_datagen<span class="variable">$</span> make</span><br></pre></td></tr></table></figure>
<blockquote>
<p>出错啦：<br>gen_random_text.cpp:43:23: warning: ISO C++ forbids converting a string constant to ‘char<em>’ [-Wwrite-strings]<br>     char</em> alpha_temp2=”/final.other”;<br>                       ^<del>~</del><br>gen_random_text.cpp:44:32: error: ‘strlen’ was not declared in this scope<br>     char* alphafile = new char[strlen(alpha_temp1)+strlen(modeldirname)+strlen(alpha_temp2)+1];     <img src="https://img-blog.csdnimg.cn/20191111175707847.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">                     出错原因：<br>     1. warning: ISO C++ forbids converting a string constant to ‘char<em>’ [-Wwrite-strings]<br>    *</em>出现这样的警告是因为在c和c++中，赋值操作的时候，等号两边的变量类型不一样，那么编译器会进行一种叫做 implicit conversion的操作来使得变量可以被赋值。将右边的常量强制类型转换成一个指针，也就是在修改一个const常量。编译运行的结果会因编译器和操作系统共同决定，有的编译器会通过，有的会抛异常，就算过了也可能因为操作系统的敏感性而被杀掉。像这种直接将string literal赋值给指针的操作被开发者们认为是deprecated，只不过由于以前很多代码都有这种习惯，为了兼容，就保留下来了。所以，为了消除警告，可以在程序前添加#pragma GCC diagnostic ignored “-Wwrite-strings”。**<br>    2.  error: ‘strlen’ was not declared in this scope<br>        <strong>编译器默认没有包含cstring，所以需要添加cstring头文件，在程序开始前添加头文件#include<cstring></strong><br>解决方案：<br>先make clean一下<img src="https://img-blog.csdnimg.cn/20191111180002689.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70" alt="在这里插入图片描述">在gen_random_text.cpp和pgen_random_text.cpp中添加<br>    <strong>#include<cstring><br>    #pragma GCC diagnostic ignored “-Wwrite-strings”</strong><br><img src="https://img-blog.csdnimg.cn/20191111180053328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_8,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>    再重新make编译<br>参考资料：<br><a href="https://www.youtube.com/watch?v=PZQaN9wTIsQ" target="_blank" rel="noopener">https://www.youtube.com/watch?v=PZQaN9wTIsQ</a><br><a href="https://blog.csdn.net/VVVLeHr/article/details/86697346" target="_blank" rel="noopener">https://blog.csdn.net/VVVLeHr/article/details/86697346</a></p>
</blockquote>
<p>Ok,如果没有出问题的话，会出现如下图所示<br><img src="https://img-blog.csdnimg.cn/20191111180634265.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">Compile Text data generate 完成。</p>
<h2 id="4-进行数据生成器-Graph-data-generate的编译"><a href="#4-进行数据生成器-Graph-data-generate的编译" class="headerlink" title="4    进行数据生成器 Graph data generate的编译"></a>4    进行数据生成器 Graph data generate的编译</h2><p>nano@nano10:/opt/module/BigDataBench5.0_MicroBenchmark/BigDataGeneratorSuite/Graph_datagen$ make</p>
<blockquote>
<p>出错啦</p>
<ol>
<li>错误1<br><img src="https://img-blog.csdnimg.cn/20191111180823706.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>出错原因：snap.o需要重新编译，进入Snap-core目录下，重新make一下，生成新的Snap.o目标文件，然后移到父目录同级下。<br>If there are some error about the incompatible of Snap when executes make command, users need to recompile the snap-core and update the Snap.O:<br>$ cd snap-core $ make $ mv Snap.o ../     And the execute the make command under directory of BigDataGeneratorSuite/Graph_datagen again: $ cd ../  $ make<br>解决方案：进入snap-core目录下，重新make编译该目录下的文件。<br>参考资料：<a href="http://www.benchcouncil.org/BigDataBench/files/BigDataBench5.0-User-Manual.pdf" target="_blank" rel="noopener">http://www.benchcouncil.org/BigDataBench/files/BigDataBench5.0-User-Manual.pdf</a></li>
<li>错误2<br><img src="https://img-blog.csdnimg.cn/20191111181609379.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_8,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>出错原因：没有Makefile.config这个文件<br>解决方案：找一个或者自己写一个Makefile.config<br>下载地址：<a href="https://github.com/AthenaHe/BeanchMark/blob/master/Makefile.config" target="_blank" rel="noopener">https://github.com/AthenaHe/BeanchMark/blob/master/Makefile.config</a></li>
<li>错误3<br> <img src="https://img-blog.csdnimg.cn/20191111181744927.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>出错原因：<br>（1）../glib-core/ds.h:280:5: warning: this ‘for’ clause does not guard… [-Wmisleading-indentation]<br>  for (int i=0; i&lt;Len(); i++) if(ValV[i]!=Tup[i]){return false;} return true; }<br> ../glib-core/linalg.cpp:985:9: warning: this ‘else’ clause does not guard… [-Wmisleading-indentation]<br> 由于编译环境的不同，高版本的编译环境更加严格，for后面即使只有一条语句，也要加花括号。<br>解决方案：<br> 打开../glib-core/ds.h文件，找到第280行，for循环后面相应位置添加花括号{}；打开../glib-core/linalg.cpp文件，找到第985行。else后面相应位置添加花括号{}。<br><img src="https://img-blog.csdnimg.cn/2019111118184034.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70" alt="在这里插入图片描述">)<img src="https://img-blog.csdnimg.cn/20191111181850363.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>（2）../glib-core/bd.cpp:13:21: note: forward declaration of ‘struct __exception’<br>int _matherr(struct __exception* e)<br>解决方案：<br>在bd.cpp中添加结构体：<br>struct __exception {<br> int    type;      /* Exception type <em>/<br> char</em>  name;      /* Name of function causing exception <em>/<br> double arg1;      /</em> 1st argument to function <em>/<br> double arg2;      /</em> 2nd argument to function <em>/<br> double retval;    /</em> Function return value */<br>};<br><img src="https://img-blog.csdnimg.cn/20191111181945752.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70" alt="在这里插入图片描述"><ol start="5">
<li>进行数据生成器Table data generate的编译<br>nano@nano1:/opt/module/BigDataBench5.0/BigDataGeneratorSuite$ cd Table_datagen/personal_generator/<br>nano@nano1:/opt/module/BigDataBench5.0/BigDataGeneratorSuite/Table_datagen/personal_generator$ make<br><img src="https://img-blog.csdnimg.cn/20191111182029487.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70" alt="在这里插入图片描述"></li>
</ol>
</li>
</ol>
</blockquote>
<h2 id="6-数据生成及处理"><a href="#6-数据生成及处理" class="headerlink" title="6. 数据生成及处理"></a>6. 数据生成及处理</h2><p><strong>注意：有些脚本中没有加MAHOUT_HOME地址，执行会报错，自己在脚本中手动添加BigDatabench中自带的mahout地址，或者在环境变量中配置</strong></p>
<ul>
<li>terasort<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">生成<span class="number">1</span>G的数据</span><br><span class="line">	nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>/Hadoop/Sort<span class="variable">$</span> ./genData<span class="literal">-sort</span>.sh <span class="number">1</span></span><br><span class="line">	<span class="comment"># Generating command: ./genData-sort.sh &lt;size&gt;</span></span><br><span class="line">	<span class="comment">#       size: the input data size, GB</span></span><br><span class="line">	a=<span class="variable">$1</span></span><br><span class="line">	let L=<span class="variable">$a</span>*<span class="number">10000000</span></span><br><span class="line">	<span class="comment">#-----------------generating input data---------------</span></span><br><span class="line">	<span class="variable">$HADOOP_HOME</span>/bin/hadoop dfs <span class="literal">-rmr</span> /hadoop/terasort/terasort-<span class="variable">$</span>&#123;a&#125;G</span><br><span class="line">	<span class="variable">$HADOOP_HOME</span>/bin/hadoop jar <span class="variable">$</span>&#123;HADOOP_HOME&#125;/share/hadoop/mapreduce/hadoop<span class="literal">-mapreduce</span><span class="literal">-examples</span>-*.jar teragen <span class="variable">$L</span> /hadoop/terasort/terasort-<span class="variable">$</span>&#123;a&#125;G</span><br><span class="line">	<span class="variable">$HADOOP_HOME</span>/bin/hadoop dfs <span class="literal">-rmr</span> /hadoop/terasort/tera<span class="built_in">sort-out</span></span><br><span class="line">运行工作负载</span><br><span class="line">	nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>/Hadoop/Sort<span class="variable">$</span> ./run<span class="literal">-terasort</span>.sh <span class="number">1</span></span><br><span class="line">	<span class="comment"># Running command: ./run-terasort.sh &lt;size&gt;</span></span><br><span class="line">	<span class="comment">#       size: the input data size, GB</span></span><br><span class="line">	a=<span class="variable">$1</span></span><br><span class="line">	<span class="comment">#-----------------running hadoop terasort-------------</span></span><br><span class="line">	<span class="variable">$HADOOP_HOME</span>/bin/hadoop jar <span class="variable">$</span>&#123;HADOOP_HOME&#125;/share/hadoop/mapreduce/hadoop<span class="literal">-mapreduce</span><span class="literal">-examples</span>-*.jar terasort /hadoop/terasort/terasort-<span class="variable">$</span>&#123;a&#125;G /hadoop/terasort/tera<span class="built_in">sort-out</span></span><br></pre></td></tr></table></figure></li>
<li>Wordcount</li>
</ul>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">生成<span class="number">1</span>G的数据</span><br><span class="line">	nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>/Hadoop/wordcount<span class="variable">$</span>./genData<span class="literal">-wc</span>.sh <span class="number">1</span></span><br><span class="line">	<span class="comment"># Generating command: ./genData-wc.sh &lt;size&gt;</span></span><br><span class="line">	<span class="comment">#       size: the input data size, GB</span></span><br><span class="line">	<span class="comment">#----------------------------genenrate-data----------------------------#</span></span><br><span class="line">	curdir=`pwd`</span><br><span class="line">	a=<span class="variable">$1</span></span><br><span class="line">	    let L=a*<span class="number">2</span></span><br><span class="line">	    cd ../../BigDataGeneratorSuite/Text_datagen/</span><br><span class="line">	    rm <span class="literal">-fr</span> ./gen_data/<span class="variable">$a</span><span class="string">"GB"</span><span class="literal">-wordcountHP</span></span><br><span class="line">	    ./gen_text_data.sh lda_wiki1w <span class="variable">$L</span> <span class="number">8000</span> <span class="number">10000</span> ./gen_data/<span class="variable">$a</span><span class="string">"GB"</span><span class="literal">-wordcountHP</span></span><br><span class="line">	    <span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-rmr</span> /hadoop/wd/<span class="variable">$a</span><span class="string">"GB"</span><span class="literal">-wordcountHP</span></span><br><span class="line">	    <span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-mkdir</span> <span class="literal">-p</span> /hadoop/wd</span><br><span class="line">	    <span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-put</span> ./gen_data/<span class="variable">$a</span><span class="string">"GB"</span><span class="literal">-wordcountHP</span> /hadoop/wd</span><br><span class="line">运行工作负载</span><br><span class="line">	nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>/Hadoop/wordcount<span class="variable">$</span>./run<span class="literal">-wordcount</span>.sh <span class="number">1</span></span><br><span class="line">	<span class="comment"># Running command: ./run-wordcount.sh &lt;size&gt;</span></span><br><span class="line">	<span class="comment">#       size: the input data size, GB</span></span><br><span class="line">	a=<span class="variable">$1</span></span><br><span class="line">	<span class="comment">#-----------------------------run-workload-----------------------------#</span></span><br><span class="line">	echo <span class="string">"running wordcount"</span></span><br><span class="line">	cd <span class="variable">$curdir</span></span><br><span class="line">	cd ./externals/shell/industryPack/hadoop/workloads/wordcount</span><br><span class="line">	<span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-rmr</span> /hadoop/wd/wordcountHP<span class="literal">-result</span></span><br><span class="line">	<span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop jar <span class="variable">$</span>&#123;HADOOP_HOME&#125;/share/hadoop/mapreduce/hadoop<span class="literal">-mapreduce</span><span class="literal">-examples</span>-*.jar  wordcount  /hadoop/wd/<span class="variable">$a</span><span class="string">"GB"</span><span class="literal">-wordcountHP</span>  /hadoop/wd/wordcountHP<span class="literal">-result</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Grep<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">生成<span class="number">1</span>G的数据</span><br><span class="line">	nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>/Hadoop/Grep<span class="variable">$</span>./genData<span class="literal">-grep</span>.sh <span class="number">1</span></span><br><span class="line">	<span class="comment"># Generating command: ./genData-grep.sh &lt;size&gt;</span></span><br><span class="line">	<span class="comment">#       size: the input data size, GB</span></span><br><span class="line">	<span class="comment">#----------------------------genenrate-data----------------------------#</span></span><br><span class="line">	curdir=`pwd`</span><br><span class="line">	a=<span class="variable">$1</span></span><br><span class="line">	    let L=a*<span class="number">2</span></span><br><span class="line">	    cd ../../BigDataGeneratorSuite/Text_datagen/</span><br><span class="line">	    rm <span class="literal">-fr</span> ./gen_data/<span class="variable">$a</span><span class="string">"GB"</span><span class="literal">-grepHP</span></span><br><span class="line">	    ./gen_text_data.sh lda_wiki1w <span class="variable">$L</span> <span class="number">8000</span> <span class="number">10000</span> ./gen_data/<span class="variable">$a</span><span class="string">"GB"</span><span class="literal">-grepHP</span></span><br><span class="line">	    <span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-rmr</span> /hadoop/grep/<span class="variable">$a</span><span class="string">"GB"</span><span class="literal">-grepHP</span></span><br><span class="line">	    <span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-mkdir</span> <span class="literal">-p</span> /hadoop/grep/</span><br><span class="line">	    <span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-put</span> ./gen_data/<span class="variable">$a</span><span class="string">"GB"</span><span class="literal">-grepHP</span> /hadoop/grep/</span><br><span class="line">运行工作负载</span><br><span class="line">	nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>/Hadoop/Grep<span class="variable">$</span>./run<span class="literal">-grep</span>.sh <span class="number">1</span></span><br><span class="line">	<span class="comment"># Running command: ./run-wordcount.sh &lt;size&gt;</span></span><br><span class="line">	<span class="comment">#       size: the input data size, GB</span></span><br><span class="line">	a=<span class="variable">$1</span></span><br><span class="line">	<span class="comment">#-----------------------------run-workload-----------------------------#</span></span><br><span class="line">	echo <span class="string">"running wordcount"</span></span><br><span class="line">	cd <span class="variable">$curdir</span></span><br><span class="line">	cd ./externals/shell/industryPack/hadoop/workloads/wordcount</span><br><span class="line">	<span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-rmr</span> /hadoop/wd/wordcountHP<span class="literal">-result</span></span><br><span class="line">	<span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop jar <span class="variable">$</span>&#123;HADOOP_HOME&#125;/share/hadoop/mapreduce/hadoop<span class="literal">-mapreduce</span><span class="literal">-examples</span>-*.jar  wordcount  /hadoop/wd/<span class="variable">$a</span><span class="string">"GB"</span><span class="literal">-wordcountHP</span>  /hadoop/wd/wordcountHP<span class="literal">-result</span></span><br></pre></td></tr></table></figure></li>
<li>MD5<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"> 生成<span class="number">1</span>G的数据</span><br><span class="line">nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>_MicroBenchmark/Hadoop/MD5<span class="variable">$</span> ./genData<span class="literal">-md5</span>.sh <span class="number">1</span></span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment"># Generating command: ./genData-md5.sh &lt;size&gt;</span></span><br><span class="line"><span class="comment">#       size: the input data size, GB</span></span><br><span class="line"><span class="comment">#----------------------------genenrate-data----------------------------#</span></span><br><span class="line">a=<span class="variable">$1</span></span><br><span class="line">    let L=a*<span class="number">2</span></span><br><span class="line">    cd ../../BigDataGeneratorSuite/Text_datagen/</span><br><span class="line">    rm <span class="literal">-fr</span> ./gen_data/<span class="variable">$a</span><span class="string">"GB"</span><span class="literal">-md5HP</span></span><br><span class="line">    ./gen_text_data.sh lda_wiki1w <span class="variable">$L</span> <span class="number">8000</span> <span class="number">10000</span> ./gen_data/<span class="variable">$a</span><span class="string">"GB"</span><span class="literal">-md5HP</span></span><br><span class="line">    <span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-rmr</span> /hadoop/md5/<span class="variable">$a</span><span class="string">"GB"</span><span class="literal">-md5HP</span></span><br><span class="line">    <span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-mkdir</span> <span class="literal">-p</span> /hadoop/md5/</span><br><span class="line">    <span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-put</span> ./gen_data/<span class="variable">$a</span><span class="string">"GB"</span><span class="literal">-md5HP</span> /hadoop/md5/</span><br><span class="line">运行工作负载</span><br><span class="line">nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>_MicroBenchmark/Hadoop/MD5<span class="variable">$</span>./run<span class="literal">-md5</span>.sh <span class="number">1</span></span><br><span class="line">	<span class="comment">#!/bin/bash</span></span><br><span class="line">	  </span><br><span class="line">	<span class="comment"># Running command: ./run-md5.sh &lt;size&gt;</span></span><br><span class="line">	<span class="comment">#       size: the input data size, GB</span></span><br><span class="line">	a=<span class="variable">$1</span></span><br><span class="line">	<span class="comment">#-----------------------------run-workload-----------------------------#</span></span><br><span class="line">	echo <span class="string">"running wordcount"</span></span><br><span class="line">	<span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-rmr</span> /hadoop/md5/md5HP<span class="literal">-result</span></span><br><span class="line">	<span class="variable">$HADOOP_HOME</span>/bin/hadoop jar md5/DwarfMD5.jar DwarfMD5 /hadoop/md5/<span class="variable">$a</span><span class="string">"GB"</span><span class="literal">-md5HP</span> /hadoop/md5/md5HP<span class="literal">-result</span></span><br></pre></td></tr></table></figure></li>
<li>MatrixMult（矩阵相乘）<br>这里少了mahout的路径，要加上。MAHOUT_HOME=../apache-mahout-0.10.2-compile<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">	nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>_MicroBenchmark/Hadoop/MatrixMult<span class="variable">$</span> ./genData<span class="literal">-matMult</span>.sh <span class="number">0.2</span> <span class="number">10</span> <span class="number">10</span> <span class="number">10</span></span><br><span class="line">	<span class="comment">#!/bin/bash</span></span><br><span class="line">	<span class="comment"># Generating command: ./genData-matMult.sh &lt;sparsity&gt; &lt;row_i&gt; &lt;col_i&gt; &lt;col_j&gt; </span></span><br><span class="line">	<span class="comment">#       sparsity: the percentage of zero elements, ranges from 0 to 1.</span></span><br><span class="line">	<span class="comment">#       row_i: the row number of matrix A</span></span><br><span class="line">	<span class="comment">#       col_i: the column number of matrix A</span></span><br><span class="line">	<span class="comment">#       col_j: the column number of matrix B</span></span><br><span class="line">	<span class="comment">#----------------------------genenrate-data----------------------------#</span></span><br><span class="line">	sparsity=<span class="variable">$1</span></span><br><span class="line">	row_i=<span class="variable">$2</span></span><br><span class="line">	col_i=<span class="variable">$3</span></span><br><span class="line">	col_j=<span class="variable">$4</span></span><br><span class="line">	cd genData<span class="literal">-Matrix</span></span><br><span class="line">	rm <span class="operator">-f</span> <span class="keyword">data</span><span class="literal">-kmeans</span></span><br><span class="line">	make</span><br><span class="line">	sh generate<span class="literal">-matrix</span>.sh int <span class="variable">$row_i</span> <span class="variable">$col_i</span> <span class="variable">$sparsity</span></span><br><span class="line">	mv <span class="keyword">data</span><span class="literal">-kmeans</span> mat1</span><br><span class="line">	sh generate<span class="literal">-matrix</span>.sh int <span class="variable">$col_i</span> <span class="variable">$col_j</span> <span class="variable">$sparsity</span></span><br><span class="line">	mv <span class="keyword">data</span><span class="literal">-kmeans</span> mat2</span><br><span class="line">	<span class="variable">$HADOOP_HOME</span>/bin/hadoop fs <span class="literal">-rmr</span> /hadoop/matMult/</span><br><span class="line">	<span class="variable">$HADOOP_HOME</span>/bin/hadoop fs <span class="literal">-mkdir</span> <span class="literal">-p</span> /hadoop/matMult/</span><br><span class="line">	<span class="variable">$HADOOP_HOME</span>/bin/hadoop fs <span class="literal">-put</span> mat* /hadoop/matMult/</span><br><span class="line">	运行工作负载</span><br><span class="line">nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>_MicroBenchmark/Hadoop/MatrixMult<span class="variable">$</span> ./run<span class="literal">-matMult</span>.sh <span class="number">0.2</span> <span class="number">10</span> <span class="number">10</span> <span class="number">10</span></span><br><span class="line">	<span class="comment">#!/bin/bash  </span></span><br><span class="line">	<span class="comment"># Running command: ./run-matMult.sh &lt;sparsity&gt; &lt;row_i&gt; &lt;col_i&gt; &lt;col_j&gt; </span></span><br><span class="line">	<span class="comment">#       sparsity: the percentage of zero elements, ranges from 0 to 1.</span></span><br><span class="line">	<span class="comment">#       row_i: the row number of matrix A</span></span><br><span class="line">	<span class="comment">#       col_i: the column number of matrix A</span></span><br><span class="line">	<span class="comment">#       col_j: the column number of matrix B</span></span><br><span class="line">	sparsity=<span class="variable">$1</span></span><br><span class="line">	row_i=<span class="variable">$2</span></span><br><span class="line">	col_i=<span class="variable">$3</span></span><br><span class="line">	col_j=<span class="variable">$4</span></span><br><span class="line">	MAHOUT_HOME=../apache<span class="literal">-mahout</span><span class="literal">-0</span>.<span class="number">10.2</span><span class="literal">-compile</span></span><br><span class="line">	<span class="comment">#-----------------------------run-workload-----------------------------#</span></span><br><span class="line">	echo <span class="string">"running matMult"</span></span><br><span class="line">	<span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-rmr</span> /hadoop/matMult/mat*<span class="literal">-seq</span> /hadoop/matMult/mat<span class="literal">-out</span></span><br><span class="line">	</span><br><span class="line">	<span class="variable">$MAHOUT_HOME</span>/bin/mahout seqdirectory -<span class="literal">-input</span> /hadoop/matMult/mat1 -<span class="literal">-output</span> /hadoop/matMult/mat1<span class="literal">-seq</span></span><br><span class="line">	<span class="variable">$MAHOUT_HOME</span>/bin/mahout seqdirectory -<span class="literal">-input</span> /hadoop/matMult/mat2 -<span class="literal">-output</span> /hadoop/matMult/mat2<span class="literal">-seq</span></span><br><span class="line">	<span class="variable">$</span>&#123;MAHOUT_HOME&#125;/bin/mahout matrixmult \</span><br><span class="line">	        -<span class="literal">-numRowsA</span> <span class="variable">$row_i</span> \</span><br><span class="line">	        -<span class="literal">-numColsA</span> <span class="variable">$col_i</span> \</span><br><span class="line">	        -<span class="literal">-numRowsB</span> <span class="variable">$col_i</span> \</span><br><span class="line">	        -<span class="literal">-numColsB</span> <span class="variable">$col_j</span> \</span><br><span class="line">	        -<span class="literal">-inputPathA</span> /hadoop/matMult/mat1<span class="literal">-seq</span> \</span><br><span class="line">	        -<span class="literal">-inputPathB</span> /hadoop/matMult/mat2<span class="literal">-seq</span> \</span><br><span class="line">	        -<span class="literal">-outputPath</span> /hadoop/matMult/mat<span class="literal">-out</span></span><br><span class="line">	</span><br><span class="line">	echo <span class="string">"hadoop matrix mulitiply end"</span></span><br></pre></td></tr></table></figure></li>
<li>CC（Connected Component）<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>_MicroBenchmark/Hadoop/CC<span class="variable">$</span> ./genData<span class="literal">-cc</span>.sh <span class="number">5</span></span><br><span class="line">	<span class="comment">#!/bin/bash</span></span><br><span class="line">	<span class="comment"># Generating command: ./genData-cc.sh &lt;log_vertex&gt;</span></span><br><span class="line">	<span class="comment">#       log_vertex: indicates the vertex of the generated data, means vertex = 2^log_vertex</span></span><br><span class="line">	<span class="comment">#----------------------------genenrate-data----------------------------#</span></span><br><span class="line">	curdir=`pwd`</span><br><span class="line">	I=<span class="variable">$1</span></span><br><span class="line">	cd ../../BigDataGeneratorSuite/Graph_datagen</span><br><span class="line">	dir=/hadoop/cc</span><br><span class="line">	rm <span class="literal">-fr</span> ./gen_data/Google_genGraph_<span class="variable">$I</span>.txt</span><br><span class="line">	./gen_kronecker_graph  <span class="literal">-o</span>:./gen_data/Google_genGraph_<span class="variable">$I</span>.txt <span class="literal">-m</span>:<span class="string">"0.8305 0.5573; 0.4638 0.3021"</span> <span class="literal">-i</span>:<span class="variable">$I</span></span><br><span class="line">	head ./gen_data/Google_genGraph_<span class="variable">$I</span>.txt &gt; ./gen_data/Google_parameters_<span class="variable">$I</span></span><br><span class="line">	sed <span class="number">1</span>,<span class="number">4</span>d ./gen_data/Google_genGraph_<span class="variable">$I</span>.txt &gt; ./gen_data/Google_genGraph_<span class="variable">$I</span>.tmp</span><br><span class="line">	mv ./gen_data/Google_genGraph_<span class="variable">$I</span>.tmp ./gen_data/Google_genGraph_<span class="variable">$I</span>.txt</span><br><span class="line">	<span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-rmr</span> /hadoop/cc/Google_genGraph_<span class="variable">$I</span>.txt</span><br><span class="line">	<span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-mkdir</span> <span class="literal">-p</span> /hadoop/cc</span><br><span class="line">	<span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-put</span> ./gen_data/Google_genGraph_<span class="variable">$I</span>.txt /hadoop/cc</span><br><span class="line">运行工作负载</span><br><span class="line">	nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>_MicroBenchmark/Hadoop/CC<span class="variable">$</span> ./run<span class="literal">-cc</span>.sh <span class="number">5</span></span><br><span class="line">	<span class="comment">#!/bin/bash  </span></span><br><span class="line">	<span class="comment"># Running command: ./run-cc.sh &lt;log_vertex&gt;</span></span><br><span class="line">	<span class="comment">#       log_vertex: indicates the vertex of the input data, means vertex = 2^log_vertex</span></span><br><span class="line">	</span><br><span class="line">	reducers=<span class="number">12</span></span><br><span class="line">	I=<span class="variable">$1</span></span><br><span class="line">	</span><br><span class="line">	<span class="comment">#--------------------------------------------run----------------------------#</span></span><br><span class="line">	<span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-rmr</span> concmpt_curbm concmpt_tempbm concmpt_nextbm concmpt_output</span><br><span class="line">	<span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop jar pegasus<span class="literal">-2</span>.<span class="number">0</span>.jar pegasus.ConCmpt <span class="literal">-D</span> mapred.input.format<span class="class">.<span class="keyword">class</span>=<span class="title">org</span>.<span class="title">apache</span>.<span class="title">hadoop</span>.<span class="title">mapred</span>.<span class="title">lib</span>.<span class="title">NLineInputFormat</span> -<span class="title">D</span> <span class="title">mapred</span>.<span class="title">line</span>.<span class="title">input</span>.<span class="title">format</span>.<span class="title">linespermap</span>=2500000 /<span class="title">hadoop</span>/<span class="title">cc</span>/<span class="title">Google_genGraph_</span>$<span class="title">I</span>.<span class="title">txt</span> <span class="title">concmpt_curbm</span> <span class="title">concmpt_tempbm</span> <span class="title">concmpt_nextbm</span> <span class="title">concmpt_output</span> $<span class="title">I</span> $<span class="title">reducers</span> <span class="title">new</span> <span class="title">makesym</span></span></span><br></pre></td></tr></table></figure></li>
<li>Kmeans<br>  MAHOUT_HOME=../apache-mahout-0.10.2-compile<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">	nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>_ComponentBenchmark/Hadoop/Kmeans<span class="variable">$</span> ./genData<span class="literal">-kmeans</span>.sh <span class="number">5</span></span><br><span class="line">	<span class="comment">##!/bin/bash</span></span><br><span class="line">	<span class="comment">##</span></span><br><span class="line">	<span class="comment"># Parameter $I indicates that the vertex of the generated graph is 2^$I</span></span><br><span class="line">	<span class="comment"># Generating command: ./genData-kmeans.sh &lt;log_vertex&gt; </span></span><br><span class="line">	<span class="comment">##</span></span><br><span class="line">	I=<span class="variable">$1</span></span><br><span class="line">	cd ../../BigDataGeneratorSuite/Graph_datagen</span><br><span class="line">	rm <span class="literal">-fr</span> ./gen_data/Facebook_genGragh_<span class="variable">$I</span>.txt</span><br><span class="line">	./gen_kronecker_graph  <span class="literal">-o</span>:./gen_data/Facebook_genGragh_<span class="variable">$I</span>.txt <span class="literal">-m</span>:<span class="string">"0.9999 0.5887; 0.6254 0.3676"</span> <span class="literal">-i</span>:<span class="variable">$I</span></span><br><span class="line">	head <span class="literal">-4</span> ./gen_data/Facebook_genGragh_<span class="variable">$I</span>.txt &gt; ./gen_data/Facebook_parameters_<span class="variable">$I</span></span><br><span class="line">	sed <span class="number">1</span>,<span class="number">4</span>d ./gen_data/Facebook_genGragh_<span class="variable">$I</span>.txt &gt; ./gen_data/Facebook_genGragh_<span class="variable">$I</span>.tmp</span><br><span class="line">	mv ./gen_data/Facebook_genGragh_<span class="variable">$I</span>.tmp ./gen_data/Facebook_genGragh_<span class="variable">$I</span>.txt</span><br><span class="line">	sed <span class="string">'s/[[:space:]][[:space:]]*/ /g'</span> ./gen_data/Facebook_genGragh_<span class="variable">$I</span>.txt &gt;./gen_data/testdata</span><br><span class="line">	<span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-rmr</span> testdata</span><br><span class="line">	<span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-put</span> ./gen_data/testdata</span><br><span class="line">运行工作负载</span><br><span class="line">	nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>_ComponentBenchmark/Hadoop/Kmeans<span class="variable">$</span> ./run<span class="literal">-Kmeans</span>.sh <span class="number">0.4</span> <span class="number">0.1</span> <span class="number">0.1</span> <span class="number">5</span></span><br><span class="line">	<span class="comment">##!/bin/bash</span></span><br><span class="line">	<span class="comment">##</span></span><br><span class="line">	<span class="comment"># Kmeans running command:</span></span><br><span class="line">	<span class="comment"># ./run-Kmeans.sh &lt;t1&gt; &lt;t2&gt; &lt;cd&gt; &lt;x&gt;</span></span><br><span class="line">	<span class="comment">#       t1: T1 threshold value (0-1), such as 0.4</span></span><br><span class="line">	<span class="comment">#       t2: T2 threshold value (0-1), such as 0.1</span></span><br><span class="line">	<span class="comment">#       cd: The convergence delta value (0-1), such as 0.1</span></span><br><span class="line">	<span class="comment">#       x: The max iteration number</span></span><br><span class="line">	<span class="comment">##</span></span><br><span class="line">	<span class="comment">#-----------------------------------run--------------------------------------------#</span></span><br><span class="line">	MAHOUT_HOME=../apache<span class="literal">-mahout</span><span class="literal">-0</span>.<span class="number">10.2</span><span class="literal">-compile</span></span><br><span class="line">	<span class="variable">$HADOOP_HOME</span>/bin/hadoop dfs <span class="literal">-rmr</span> output</span><br><span class="line">	<span class="variable">$</span>&#123;MAHOUT_HOME&#125;/bin/mahout org.apache.mahout.clustering.syntheticcontrol.kmeans.Job \</span><br><span class="line">	        <span class="literal">-i</span> testdata \</span><br><span class="line">	        <span class="literal">-o</span> output \</span><br><span class="line">	        <span class="literal">-dm</span> org.apache.mahout.common.distance.CosineDistanceMeasure \</span><br><span class="line">	        <span class="literal">-t1</span> <span class="variable">$1</span> \</span><br><span class="line">	        <span class="literal">-t2</span> <span class="variable">$2</span> \</span><br><span class="line">	        <span class="literal">-cd</span> <span class="variable">$3</span> \</span><br><span class="line">	        <span class="literal">-x</span> <span class="variable">$4</span> \</span><br></pre></td></tr></table></figure></li>
<li>Pagerank<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>_ComponentBenchmark/Hadoop/PageRank<span class="variable">$</span> ./genData<span class="literal">-pagerank</span>.sh <span class="number">5</span></span><br><span class="line">	<span class="comment">#!/bin/bash</span></span><br><span class="line">	<span class="comment">##</span></span><br><span class="line">	<span class="comment"># Parameter $I indicates that the vertex of the generated graph is 2^$I</span></span><br><span class="line">	<span class="comment"># Generating command: ./genData-pagerank.sh &lt;log_vertex&gt; </span></span><br><span class="line">	<span class="comment">##</span></span><br><span class="line">	<span class="comment">#----------------------------genenrate-data----------------------------#</span></span><br><span class="line">	I=<span class="variable">$1</span></span><br><span class="line">	cd ../../BigDataGeneratorSuite/Graph_datagen</span><br><span class="line">	dir=/hadoop/pagerank</span><br><span class="line">	rm <span class="literal">-fr</span> ./gen_data/Google_genGraph_<span class="variable">$I</span>.txt</span><br><span class="line">	./gen_kronecker_graph  <span class="literal">-o</span>:./gen_data/Google_genGraph_<span class="variable">$I</span>.txt <span class="literal">-m</span>:<span class="string">"0.8305 0.5573; 0.4638 0.3021"</span> <span class="literal">-i</span>:<span class="variable">$I</span></span><br><span class="line">	head ./gen_data/Google_genGraph_<span class="variable">$I</span>.txt &gt; ./gen_data/Google_parameters_<span class="variable">$I</span></span><br><span class="line">	sed <span class="number">1</span>,<span class="number">4</span>d ./gen_data/Google_genGraph_<span class="variable">$I</span>.txt &gt; ./gen_data/Google_genGraph_<span class="variable">$I</span>.tmp</span><br><span class="line">	mv ./gen_data/Google_genGraph_<span class="variable">$I</span>.tmp ./gen_data/Google_genGraph_<span class="variable">$I</span>.txt</span><br><span class="line">	<span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-rmr</span> /hadoop/pagerank/Google_genGraph_<span class="variable">$I</span>.txt</span><br><span class="line">	<span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-mkdir</span> <span class="literal">-p</span> /hadoop/pagerank</span><br><span class="line">	<span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-put</span> ./gen_data/Google_genGraph_<span class="variable">$I</span>.txt /hadoop/pagerank</span><br></pre></td></tr></table></figure>
运行工作负载<br>nano@nano1:/opt/module/BigDataBench5.0_ComponentBenchmark/Hadoop/PageRank$./run-pagerank.sh 5<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash  </span></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"><span class="comment"># Parameter $I indicates that the vertex of the generated graph is 2^$I</span></span><br><span class="line"><span class="comment"># Running command: ./run-pagerank.sh &lt;log_vertex&gt; </span></span><br><span class="line"><span class="comment">##</span></span><br><span class="line">I=<span class="variable">$1</span></span><br><span class="line"><span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-rmr</span> /hadoop/pagerank/prtemp /hadoop/pagerank/output pr_distr pr_minmax pr_vector</span><br><span class="line"><span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop jar pegasus<span class="literal">-2</span>.<span class="number">0</span>.jar pegasus.PagerankNaive /hadoop/pagerank/Google_genGraph_<span class="variable">$I</span>.txt /hadoop/pagerank/prtemp /hadoop/pagerank/output <span class="number">450</span> <span class="number">4</span> <span class="number">3</span> nosym new</span><br></pre></td></tr></table></figure></li>
<li>RandSample<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">生成<span class="number">1</span>G的数据</span><br><span class="line">	nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>_MicroBenchmark/Hadoop/randSample<span class="variable">$</span> ./genData<span class="literal">-randSample</span>.sh <span class="number">1</span></span><br><span class="line">	<span class="comment"># Generating command: ./genData-randSample.sh &lt;size&gt;</span></span><br><span class="line">	<span class="comment">#       size: the input data size, GB</span></span><br><span class="line">	<span class="comment">#----------------------------genenrate-data----------------------------#</span></span><br><span class="line">	curdir=`pwd`</span><br><span class="line">	a=<span class="variable">$1</span></span><br><span class="line">	    let L=a*<span class="number">2</span></span><br><span class="line">	    cd ../../BigDataGeneratorSuite/Text_datagen/</span><br><span class="line">	    rm <span class="literal">-fr</span> ./gen_data/<span class="variable">$a</span><span class="string">"GB"</span><span class="literal">-randsampleHP</span></span><br><span class="line">	    ./gen_text_data.sh lda_wiki1w <span class="variable">$L</span> <span class="number">8000</span> <span class="number">10000</span> ./gen_data/<span class="variable">$a</span><span class="string">"GB"</span><span class="literal">-randsampleHP</span></span><br><span class="line">	    <span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-rmr</span> /hadoop/randsample/<span class="variable">$a</span><span class="string">"GB"</span><span class="literal">-randsampleHP</span></span><br><span class="line">	    <span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-mkdir</span> <span class="literal">-p</span> /hadoop/randsample</span><br><span class="line">	    <span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-put</span> ./gen_data/<span class="variable">$a</span><span class="string">"GB"</span><span class="literal">-randsampleHP</span> /hadoop/randsample</span><br><span class="line">```	</span><br><span class="line">	运行工作负载</span><br><span class="line">	nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>_MicroBenchmark/Hadoop/randSample<span class="variable">$</span> ./run<span class="literal">-randSample</span>.sh <span class="number">1</span> <span class="number">0.3</span></span><br><span class="line">```powershell</span><br><span class="line">	<span class="comment"># Running command: ./run-randSample.sh &lt;size&gt; &lt;sample_ratio&gt;</span></span><br><span class="line">	<span class="comment">#       size: the input data size, GB</span></span><br><span class="line">	<span class="comment">#       sample_ratio: the sampling ratio, ranges from 0 to 1.</span></span><br><span class="line">	curdir=`pwd`</span><br><span class="line">	a=<span class="variable">$1</span></span><br><span class="line">	<span class="comment">#-----------------------------run-workload-----------------------------#</span></span><br><span class="line">	echo <span class="string">"running randsample"</span></span><br><span class="line">	<span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-rmr</span> /hadoop/randsample/randsampleHP<span class="literal">-result</span></span><br><span class="line">	<span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop jar RandSample/out/artifacts/RandSample_jar/RandSample.jar RandSample /hadoop/randsample/<span class="variable">$a</span><span class="string">"GB"</span><span class="literal">-randsampleHP</span>  /hadoop/randsample/randsampleHP<span class="literal">-result</span> <span class="variable">$2</span></span><br></pre></td></tr></table></figure></li>
<li>CF（collaborative Filtering）<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">生成<span class="number">1</span>G的数据</span><br><span class="line">	nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>_ComponentBenchmark/Hadoop/CF<span class="variable">$</span> ./genData<span class="literal">-cf</span>.sh <span class="number">1</span></span><br><span class="line">	<span class="comment">#Command for generating data:</span></span><br><span class="line">	<span class="comment">#       ./genData-cf.sh &lt;size&gt; #GB</span></span><br><span class="line">	<span class="comment">#</span></span><br><span class="line">	</span><br><span class="line">	a=`expr <span class="variable">$1</span> \* <span class="number">1024</span>`</span><br><span class="line">	</span><br><span class="line">	<span class="comment">#-----------------generating input data---------------</span></span><br><span class="line">	rm <span class="literal">-rf</span> genData<span class="literal">-CF</span>/als_input.txt</span><br><span class="line">	<span class="variable">$HADOOP_HOME</span>/bin/hadoop dfs <span class="literal">-rmr</span> /hadoop/cf/cf-<span class="variable">$</span>&#123;<span class="number">1</span>&#125;G</span><br><span class="line">	cd genData<span class="literal">-CF</span></span><br><span class="line">	make</span><br><span class="line">	./ALS<span class="literal">-DataGen</span> <span class="variable">$a</span></span><br><span class="line">	<span class="variable">$HADOOP_HOME</span>/bin/hadoop fs <span class="literal">-mkdir</span> <span class="literal">-p</span> /hadoop/cf/</span><br><span class="line">	<span class="variable">$HADOOP_HOME</span>/bin/hadoop fs als_input.txt /hadoop/cf/cf-<span class="variable">$</span>&#123;<span class="number">1</span>&#125;G</span><br><span class="line">	<span class="variable">$HADOOP_HOME</span>/bin/hadoop dfs <span class="literal">-rmr</span> /hadoop/cf/cf<span class="literal">-out</span> /hadoop/cf/temp</span><br></pre></td></tr></table></figure>
 运行工作负载<br> nano@nano1:/opt/module/BigDataBench5.0_ComponentBenchmark/Hadoop/CF$ ./run-cf.sh 1<br> 注意：脚本中没有加MAHOUT_HOME地址，执行会报错，自己在脚本中手动添加BigDatabench中自带的mahout地址，或者在环境变量中配置<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash </span><br><span class="line">#Run command: .&#x2F;run-cf.sh &lt;size&gt; &lt;numFeatures&gt; &lt;numIterations&gt; &lt;lambda&gt;</span><br><span class="line">#       size: the input data size, GB</span><br><span class="line">#       numFeatures: the number of features</span><br><span class="line">#       numIterations: the number of features</span><br><span class="line">#       lambda: regularization parameter</span><br><span class="line">MAHOUT_HOME&#x3D;..&#x2F;apache-mahout-0.10.2-compile</span><br><span class="line">#-----------------running hadoop cf-------------</span><br><span class="line">$&#123;MAHOUT_HOME&#125;&#x2F;bin&#x2F;mahout parallelALS \</span><br><span class="line">        -i &#x2F;hadoop&#x2F;cf&#x2F;cf-$&#123;1&#125;G \</span><br><span class="line">        -o &#x2F;hadoop&#x2F;cf&#x2F;cf-out \</span><br><span class="line">        --numFeatures $2 \</span><br><span class="line">        --numIterations $3 \</span><br><span class="line">        --lambda $4 \</span><br><span class="line">        --tempDir &#x2F;hadoop&#x2F;cf&#x2F;temp</span><br><span class="line">#-----------------killing monitor script--------------</span><br><span class="line">echo &quot;hadoop cf end&quot;</span><br></pre></td></tr></table></figure></li>
<li>Bayes<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">生成<span class="number">1</span>G的数据</span><br><span class="line">	nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>_ComponentBenchmark/Hadoop/Bayes<span class="variable">$</span> ./genData<span class="literal">-bayes</span>.sh <span class="number">1</span></span><br><span class="line">	<span class="comment">#!/bin/bash	  </span></span><br><span class="line">	<span class="comment">#</span></span><br><span class="line">	<span class="comment">#The parameter $1 indicates the data size (GB) to generate</span></span><br><span class="line">	<span class="comment">#Command for generate data: ./genData-bayes.sh &lt;size&gt; #GB</span></span><br><span class="line">	<span class="comment">#	</span></span><br><span class="line">	<span class="comment">#------------generate-data---------------------</span></span><br><span class="line">	a=<span class="variable">$1</span></span><br><span class="line">	cd ../../BigDataGeneratorSuite/Text_datagen/</span><br><span class="line">	rm <span class="literal">-rf</span> ./gen_data/<span class="keyword">data</span><span class="literal">-naivebayes</span></span><br><span class="line">	    let L=a*<span class="number">2</span></span><br><span class="line">	    ./gen_text_data.sh amazonMR1 <span class="variable">$L</span> <span class="number">1900</span> <span class="number">11500</span> ./gen_data/<span class="keyword">data</span><span class="literal">-naivebayes</span>/amazonMR1</span><br><span class="line">	    ./gen_text_data.sh amazonMR2 <span class="variable">$L</span> <span class="number">1900</span> <span class="number">11500</span> ./gen_data/<span class="keyword">data</span><span class="literal">-naivebayes</span>/amazonMR2</span><br><span class="line">	    ./gen_text_data.sh amazonMR3 <span class="variable">$L</span> <span class="number">1900</span> <span class="number">11500</span> ./gen_data/<span class="keyword">data</span><span class="literal">-naivebayes</span>/amazonMR3</span><br><span class="line">	    ./gen_text_data.sh amazonMR4 <span class="variable">$L</span> <span class="number">1900</span> <span class="number">11500</span> ./gen_data/<span class="keyword">data</span><span class="literal">-naivebayes</span>/amazonMR4</span><br><span class="line">	    ./gen_text_data.sh amazonMR5 <span class="variable">$L</span> <span class="number">1900</span> <span class="number">11500</span> ./gen_data/<span class="keyword">data</span><span class="literal">-naivebayes</span>/amazonMR5</span><br><span class="line">	<span class="comment">#-------------------------------------put-data----------------------------#</span></span><br><span class="line">	    <span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-rmr</span> /hadoop/Bayes/*</span><br><span class="line">	    <span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-mkdir</span> <span class="literal">-p</span> /hadoop/Bayes</span><br><span class="line">	    <span class="variable">$</span>&#123;HADOOP_HOME&#125;/bin/hadoop fs <span class="literal">-put</span> ./gen_data/<span class="keyword">data</span><span class="literal">-naivebayes</span> /hadoop/Bayes/</span><br></pre></td></tr></table></figure>
运行工作负载<br>nano@nano1:/opt/module/BigDataBench5.0_ComponentBenchmark/Hadoop/Bayes$ ./run-bayes.sh<br>注意：脚本中没有加MAHOUT_HOME地址，执行会报错，自己在脚本中手动添加BigDatabench中自带的mahout地址，或者在环境变量中配置<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash  </span></span><br><span class="line"><span class="comment"># Run command: ./run-bayes.sh</span></span><br><span class="line">MAHOUT_HOME=../apache<span class="literal">-mahout</span><span class="literal">-0</span>.<span class="number">10.2</span><span class="literal">-compile</span></span><br><span class="line"><span class="comment">#--------------------------------------run-workload-----------------------#</span></span><br><span class="line"><span class="comment">#Generates input dataset for training &amp; testing classifier</span></span><br><span class="line">dir=/hadoop/Bayes</span><br><span class="line">echo <span class="string">"Creating sequence files from naivebayes-naivebayes data"</span></span><br><span class="line"> <span class="variable">$</span>&#123;MAHOUT_HOME&#125;/bin/mahout seqdirectory \</span><br><span class="line">  <span class="literal">-i</span> /hadoop/Bayes/<span class="keyword">data</span><span class="literal">-naivebayes</span> \</span><br><span class="line">  <span class="literal">-o</span> /hadoop/Bayes/naivebayes<span class="literal">-seq</span> <span class="literal">-ow</span></span><br><span class="line">echo <span class="string">"Converting sequence files to vectors"</span></span><br><span class="line"> <span class="variable">$</span>&#123;MAHOUT_HOME&#125;/bin/mahout seq2sparse \</span><br><span class="line">  <span class="literal">-i</span> /hadoop/Bayes/naivebayes<span class="literal">-seq</span> \</span><br><span class="line">  <span class="literal">-o</span> /hadoop/Bayes/naivebayes<span class="literal">-vectors</span>  <span class="literal">-lnorm</span> <span class="literal">-nv</span>  <span class="literal">-wt</span> tfidf</span><br><span class="line">echo <span class="string">"Creating training and holdout set with a random 80-20 split of the generated vector dataset"</span></span><br><span class="line"> <span class="variable">$</span>&#123;MAHOUT_HOME&#125;/bin/mahout split \</span><br><span class="line">  <span class="literal">-i</span> /hadoop/Bayes/naivebayes<span class="literal">-vectors</span>/tfidf<span class="literal">-vectors</span> \</span><br><span class="line">  -<span class="literal">-trainingOutput</span> /hadoop/Bayes/naivebayes<span class="literal">-train</span><span class="literal">-vectors</span> \</span><br><span class="line">  -<span class="literal">-testOutput</span> /hadoop/Bayes/naivebayes<span class="literal">-test</span><span class="literal">-vectors</span>  \</span><br><span class="line">  -<span class="literal">-randomSelectionPct</span> <span class="number">70</span> -<span class="literal">-overwrite</span> -<span class="literal">-sequenceFiles</span> <span class="literal">-xm</span> sequential</span><br><span class="line"><span class="comment">#Trains the classifier</span></span><br><span class="line">echo <span class="string">"Training Naive Bayes model"</span></span><br><span class="line"> <span class="variable">$</span>&#123;MAHOUT_HOME&#125;/bin/mahout trainnb \</span><br><span class="line">  <span class="literal">-i</span> /hadoop/Bayes/naivebayes<span class="literal">-train</span><span class="literal">-vectors</span>  \</span><br><span class="line">  <span class="literal">-o</span> /hadoop/Bayes/model \</span><br><span class="line">  <span class="literal">-li</span> /hadoop/Bayes/labelindex \</span><br><span class="line">  <span class="literal">-ow</span> <span class="comment">#$c</span></span><br><span class="line"><span class="comment">#------------------------------------------run------------------------------#</span></span><br><span class="line">hadoop dfs <span class="literal">-rmr</span> /hadoop/Bayes/naivebayes<span class="literal">-testing</span></span><br><span class="line"><span class="variable">$</span>&#123;MAHOUT_HOME&#125;/bin/mahout testnb \</span><br><span class="line"> <span class="literal">-i</span> /hadoop/Bayes/naivebayes<span class="literal">-test</span><span class="literal">-vectors</span> \</span><br><span class="line"> <span class="literal">-m</span> /hadoop/Bayes/model \</span><br><span class="line"> <span class="literal">-l</span> /hadoop/Bayes/labelindex \</span><br><span class="line"> <span class="literal">-ow</span> <span class="literal">-o</span> /hadoop/Bayes/naivebayes<span class="literal">-testing</span> <span class="comment">#$c</span></span><br></pre></td></tr></table></figure>
<img src="https://img-blog.csdnimg.cn/20191111185658916.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70" alt="在这里插入图片描述"></li>
<li>Index<br>首先进行配置<br>nano@nano1:/opt/module/BigDataBench5.0_ComponentBenchmark/Hadoop/Index/conf$ vim hibench-config.sh<br><img src="https://img-blog.csdnimg.cn/20191111185813179.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70" alt="在这里插入图片描述">nano@nano1:/opt/module/BigDataBench5.0_ComponentBenchmark/Hadoop/Index/conf$ vim configure.sh<br><img src="https://img-blog.csdnimg.cn/20191111185849328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70" alt="在这里插入图片描述"><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">生成数据</span><br><span class="line">	nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>_ComponentBenchmark/Hadoop/Index/bin<span class="variable">$</span> ./genData_Index.sh </span><br><span class="line">	<span class="comment">#!/bin/bash</span></span><br><span class="line">	bin=`dirname <span class="string">"<span class="variable">$0</span>"</span>`</span><br><span class="line">	bin=`cd <span class="string">"<span class="variable">$bin</span>"</span>; pwd`</span><br><span class="line">	</span><br><span class="line">	echo <span class="string">"========== preparing nutchindex data =========="</span></span><br><span class="line">	</span><br><span class="line">	<span class="comment"># configure</span></span><br><span class="line">	DIR=`cd <span class="variable">$bin</span>/../; pwd`</span><br><span class="line">	. <span class="string">"<span class="variable">$</span>&#123;DIR&#125;/conf/hibench-config.sh"</span></span><br><span class="line">	. <span class="string">"<span class="variable">$</span>&#123;DIR&#125;/conf/configure.sh"</span></span><br><span class="line">	</span><br><span class="line">	<span class="comment"># compress</span></span><br><span class="line">	<span class="keyword">if</span> [ <span class="variable">$COMPRESS</span> -<span class="type">eq</span> <span class="number">1</span> ]; then</span><br><span class="line">	    COMPRESS_OPT=<span class="string">"-c <span class="variable">$</span>&#123;COMPRESS_CODEC&#125;"</span></span><br><span class="line">	fi</span><br><span class="line">	</span><br><span class="line">	rm <span class="literal">-rf</span> <span class="variable">$TMPLOGFILE</span></span><br><span class="line">	hadoop dfs <span class="literal">-rmr</span> /Nutch</span><br><span class="line">	hadoop dfs <span class="literal">-mkdir</span> /Nutch</span><br><span class="line">	<span class="comment"># generate data</span></span><br><span class="line">	OPTION=<span class="string">"-t nutch \</span></span><br><span class="line"><span class="string">	        -b <span class="variable">$</span>&#123;NUTCH_BASE_HDFS&#125; \</span></span><br><span class="line"><span class="string">	        -n <span class="variable">$</span>&#123;NUTCH_INPUT&#125; \</span></span><br><span class="line"><span class="string">	        -m <span class="variable">$</span>&#123;NUM_MAPS&#125; \</span></span><br><span class="line"><span class="string">	        -r <span class="variable">$</span>&#123;NUM_REDS&#125; \</span></span><br><span class="line"><span class="string">	        -p <span class="variable">$</span>&#123;PAGES&#125; \</span></span><br><span class="line"><span class="string">	        -o sequence"</span></span><br><span class="line">	</span><br><span class="line">	<span class="variable">$HADOOP_EXECUTABLE</span> jar  ../conf/datatools.jar HiBench.DataGen <span class="variable">$</span>&#123;OPTION&#125; <span class="variable">$</span>&#123;COMPRESS_OPT&#125;</span><br><span class="line">运行工作负载</span><br><span class="line">	nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>_ComponentBenchmark/Hadoop/Index/bin<span class="variable">$</span> ./run_Index.sh</span><br><span class="line">	<span class="comment">#!/bin/bash</span></span><br><span class="line">	bin=`dirname <span class="string">"<span class="variable">$0</span>"</span>`</span><br><span class="line">	bin=`cd <span class="string">"<span class="variable">$bin</span>"</span>; pwd`</span><br><span class="line">	</span><br><span class="line">	echo <span class="string">"========== running nutchindex data =========="</span></span><br><span class="line">	<span class="comment"># configure</span></span><br><span class="line">	DIR=`cd <span class="variable">$bin</span>/../; pwd`</span><br><span class="line">	. <span class="string">"<span class="variable">$</span>&#123;DIR&#125;/conf/hibench-config.sh"</span></span><br><span class="line">	. <span class="string">"<span class="variable">$</span>&#123;DIR&#125;/conf/configure.sh"</span></span><br><span class="line">	</span><br><span class="line">	export NUTCH_HOME=<span class="variable">$BigdataBench_Home</span>/SearchEngine/Index/nutch<span class="literal">-1</span>.<span class="number">2</span><span class="literal">-hadoop1</span></span><br><span class="line">	cd <span class="variable">$NUTCH_HOME</span></span><br><span class="line">	export NUTCH_CONF_DIR=<span class="variable">$HADOOP_CONF_DIR:</span><span class="variable">$NUTCH_HOME</span>/conf</span><br><span class="line">	</span><br><span class="line">	hadoop dfs <span class="literal">-rmr</span> /Nutch/Output</span><br><span class="line">	hadoop dfs <span class="literal">-rmr</span> <span class="variable">$INPUT_HDFS</span>/indexes</span><br><span class="line">	<span class="comment"># run bench</span></span><br><span class="line">	../nutch<span class="literal">-1</span>.<span class="number">2</span><span class="literal">-hadoop1</span>/bin/nutch index <span class="variable">$COMPRESS_OPTS</span> <span class="variable">$OUTPUT_HDFS</span> <span class="variable">$INPUT_HDFS</span>/crawldb <span class="variable">$INPUT_HDFS</span>/linkdb <span class="variable">$INPUT_HDFS</span>/segments/*</span><br></pre></td></tr></table></figure>
<blockquote>
<p>出错啦：<br><img src="https://img-blog.csdnimg.cn/2019111119391582.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNDU2NjYwNQ==,size_10,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>出错原因：<br>解决方案：</p>
</blockquote>
</li>
<li>SIFT<br><a href="https://blog.csdn.net/chezhai/article/details/66044054" target="_blank" rel="noopener">SIFT详解</a>：（局部特征提取算法）尺度不变特征转换(Scale-invariant feature transform或SIFT)是一种电脑视觉的算法用来侦测与描述影像中的局部性特征，它在空间尺度中寻找极值点，并提取出其位置、尺度、旋转不变量，此算法由 David Lowe在1999年所发表，2004年完善总结。其应用范围包含物体辨识、机器人地图感知与导航、影像缝合、3D模型建立、手势辨识、影像追踪和动作比对。此算法有其专利，专利拥有者为英属哥伦比亚大学。<br>数据集下载地址<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://www.image<span class="literal">-net</span>.org/challenges/LSVRC/<span class="number">2014</span>/</span><br></pre></td></tr></table></figure>
上传数据集<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs://<span class="number">192.168</span>.<span class="number">1.101</span>:<span class="number">9000</span>/hadoop/sift/<span class="keyword">data</span>/image1G.hib</span><br></pre></td></tr></table></figure>
运行工作负载<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nano@nano1:/opt/module/BigDataBench5.<span class="number">0</span>_ComponentBenchmark/Hadoop/SIFT<span class="variable">$</span> ./run<span class="literal">-sift</span>.sh <span class="number">1</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"><span class="comment">#Running command: ./run-sift.sh &lt;imgsize&gt;</span></span><br><span class="line"><span class="comment">#       imgsize: the total size of the images, GB</span></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"><span class="comment">#----------------check whether opencv is installed--------#  </span></span><br><span class="line">isopencv=`pkg<span class="literal">-config</span> -<span class="literal">-modversion</span> opencv`</span><br><span class="line">strB=<span class="string">"Package opencv was not found"</span></span><br><span class="line">result=<span class="variable">$</span>(echo <span class="variable">$isopencv</span> | grep <span class="string">"<span class="variable">$</span>&#123;strB&#125;"</span>)</span><br><span class="line">echo <span class="variable">$result</span></span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$result</span> != <span class="string">""</span> ]];then</span><br><span class="line">echo <span class="string">"no opencv"</span></span><br><span class="line"><span class="keyword">exit</span> <span class="number">1</span></span><br><span class="line">fi</span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$1</span> -<span class="type">ge</span> <span class="number">10</span> ]];then</span><br><span class="line">a=<span class="number">10</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">a=<span class="number">1</span></span><br><span class="line">fi</span><br><span class="line"><span class="comment">#-----------------generating input data---------------</span></span><br><span class="line"><span class="variable">$HADOOP_HOME</span>/bin/hadoop dfs <span class="literal">-rmr</span> /hadoop/sift/<span class="keyword">data</span>/image<span class="variable">$</span>&#123;a&#125;G.*</span><br><span class="line"><span class="variable">$HADOOP_HOME</span>/bin/hadoop fs <span class="literal">-mkdir</span> <span class="literal">-p</span> /hadoop/sift/<span class="keyword">data</span>/</span><br><span class="line"><span class="variable">$HADOOP_HOME</span>/bin/hadoop dfs <span class="literal">-rmr</span> /hadoop/sift/sift<span class="literal">-out</span></span><br><span class="line"><span class="variable">$HADOOP_HOME</span>/bin/hadoop fs <span class="literal">-put</span> hadoop<span class="literal">-SIFT</span>/<span class="keyword">data</span>/image<span class="variable">$</span>&#123;a&#125;G.* /hadoop/sift/<span class="keyword">data</span>/</span><br><span class="line"><span class="comment">#-----------------running hadoop sift-------------</span></span><br><span class="line"><span class="variable">$HADOOP_HOME</span>/bin/hadoop jar hadoop<span class="literal">-SIFT</span>/hipi<span class="literal">-SIFT</span>/tools/sift/build/libs/sift.jar /hadoop/sift/<span class="keyword">data</span>/image<span class="variable">$</span>&#123;a&#125;G.hib /hadoop/sift/sift<span class="literal">-out</span></span><br></pre></td></tr></table></figure>






      
    </div>
    
    
    

    

    

    

<div>
  
    <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">---------本文结束啦<i class="fa fa-paw"></i>感谢您的阅读，请多指教---------</div>
    
</div>


  
</div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag"><i class="fa fa-tag"></i> 大数据</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/06/01/Linux%E4%B8%8B%E8%BD%BDGSL%E5%BA%93%E5%B9%B6%E5%AE%89%E8%A3%85/" rel="next" title="Linux下载GSL库并安装">
                <i class="fa fa-chevron-left"></i> Linux下载GSL库并安装
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/06/01/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%B3%BB%E5%88%97-B%E6%A0%91%E3%80%81B-%E6%A0%91%E3%80%81B-%E6%A0%91/" rel="prev" title="数据结构系列--B树、B+树、B*树">
                数据结构系列--B树、B+树、B*树 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=864711417&auto=1&height=66"></iframe>

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.png"
                alt="Athenahe" />
            
              <p class="site-author-name" itemprop="name">Athenahe</p>
              <p class="site-description motion-element" itemprop="description">这个一个菜鸟程序媛的小博客</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7C%20archive">
              
                  <span class="site-state-item-count">34</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/AthenaHe" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://blog.csdn.net/weixin_34566605" target="_blank" title="CSDN">
                      
                        <i class="fa fa-fw fa-crosshairs"></i>CSDN</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-首先就是下载BigDataBench安装包"><span class="nav-number">1.</span> <span class="nav-text">1. 首先就是下载BigDataBench安装包</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-解压安装包"><span class="nav-number">2.</span> <span class="nav-text">2. 解压安装包</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-进入安装目录，进行数据生成器Text-data-generate-的编译"><span class="nav-number">3.</span> <span class="nav-text">3. 进入安装目录，进行数据生成器Text data generate 的编译</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-进行数据生成器-Graph-data-generate的编译"><span class="nav-number">4.</span> <span class="nav-text">4    进行数据生成器 Graph data generate的编译</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-数据生成及处理"><span class="nav-number">5.</span> <span class="nav-text">6. 数据生成及处理</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-[object Object]"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">AthenaHe</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>








        







        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>
